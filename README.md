# ğŸ” Automated EDA (Exploratory Data Analysis) Tool

A powerful Python-based tool that automatically performs comprehensive exploratory data analysis on any dataset, generating professional reports with visualizations, statistical summaries, and data quality insights.

## ğŸ“Š Project Overview

The Automated EDA tool streamlines the data exploration process by automatically analyzing datasets and generating comprehensive reports. It provides instant insights into data quality, statistical distributions, correlations, missing values, and potential outliers without requiring manual coding.

**Key Capabilities:**
- ğŸ” **Automated Data Profiling**: Generates complete statistical summaries and data type analysis
- ğŸ“Š **Interactive Visualizations**: Creates 15+ different chart types including distributions, correlations, and missing data patterns  
- ğŸ“‹ **Professional Reports**: Outputs HTML and PDF reports with embedded visualizations and insights
- ğŸ¯ **Data Quality Assessment**: Identifies missing values, duplicates, outliers, and data inconsistencies
- ğŸ’¡ **Feature Insights**: Provides correlation analysis and feature relationship discovery
- ğŸš€ **One-Click Analysis**: Simply point to a CSV file and get comprehensive results in minutes

## âœ¨ Features

### ğŸ“ˆ Core Analytics
- **Dataset Profiling**: Automatic analysis of data types, distributions, and basic statistics
- **Statistical Summaries**: Mean, median, mode, standard deviation, skewness, kurtosis for numeric data
- **Missing Data Analysis**: Comprehensive missing value patterns and percentage calculations
- **Outlier Detection**: IQR and Z-score methods with detailed visualizations
- **Correlation Analysis**: Feature correlation matrices with heatmap visualizations
- **Data Quality Metrics**: Duplicate detection, data completeness, and consistency checks

### ğŸ¨ Visualization Engine  
- **Distribution Plots**: Histograms with KDE curves for all numeric columns
- **Categorical Analysis**: Count plots and frequency analysis for categorical variables
- **Correlation Heatmaps**: Interactive correlation matrices with customizable color schemes
- **Box Plots**: Quartile analysis and outlier visualization
- **Pairplots**: Scatter matrix showing relationships between numeric features
- **Missing Data Visualization**: Matrix plots and heatmaps showing missing data patterns
- **Summary Dashboards**: Overview plots showing data types and completeness

### ï¿½ File Format Support
- **CSV Files**: Primary input format with automatic delimiter detection
- **Excel Support**: XLSX and XLS file compatibility (planned)
- **JSON Data**: Structured data analysis (planned) 
- **Database Connectivity**: Direct SQL database analysis (planned)

### ğŸ“‹ Report Generation
- **HTML Reports**: Interactive reports with embedded plots and navigation
- **JSON Summaries**: Machine-readable results for programmatic access
- **PDF Export**: Professional PDF reports for sharing and presentations (planned)
- **Jupyter Integration**: Compatible with Jupyter notebooks for interactive analysis

## ğŸ› ï¸ Tech Stack

### Core Libraries
- **Python 3.8+**: Primary programming language
- **Pandas**: Data manipulation and analysis
- **NumPy**: Numerical computing and array operations
- **Matplotlib**: Static plotting and visualization foundation
- **Seaborn**: Statistical data visualization
- **Plotly**: Interactive plots and dashboards

### Specialized Tools
- **Jupyter Notebook**: Interactive development and analysis environment
- **ydata-profiling**: Automated profiling reports
- **missingno**: Missing data visualization
- **scipy**: Scientific computing and statistical functions
- **sweetviz**: Automated EDA report generation

### Additional Dependencies
- **argparse**: Command-line interface handling
- **logging**: Progress tracking and error reporting
- **json**: Data serialization and configuration
- **jinja2**: HTML template rendering

## ğŸ“ File Structure

```
Automated_EDA/
â”œâ”€â”€ ğŸ“ src/                     # Core source code
â”‚   â”œâ”€â”€ main_eda.py            # Main EDA analysis engine
â”‚   â”œâ”€â”€ visualizations.py      # Visualization generation module
â”‚   â””â”€â”€ __init__.py            # Package initialization
â”œâ”€â”€ ğŸ“ data/                    # Sample datasets
â”‚   â””â”€â”€ loan_approval.csv      # Example dataset for testing
â”œâ”€â”€ ğŸ“ config/                  # Configuration files
â”‚   â””â”€â”€ eda_config.json        # Analysis settings and preferences
â”œâ”€â”€ ğŸ“ eda_output/             # Generated analysis results
â”‚   â”œâ”€â”€ eda_report.html        # Main HTML report
â”‚   â”œâ”€â”€ eda_summary.json       # JSON summary of results
â”‚   â”œâ”€â”€ ğŸ“ plots/              # Generated visualization files
â”‚   â””â”€â”€ ğŸ“ reports/            # Additional profiling reports
â”œâ”€â”€ ğŸ“ notebooks/              # Jupyter notebooks (optional)
â”‚   â””â”€â”€ eda.ipynb             # Interactive EDA notebook
â”œâ”€â”€ automated_eda.py           # Main command-line script
â”œâ”€â”€ example_usage.py           # Usage examples and API demos
â”œâ”€â”€ run_eda.sh                 # Bash script for easy execution
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Makefile                   # Common tasks automation
â””â”€â”€ README.md                  # Project documentation
```

### Key Files Description
- **`automated_eda.py`**: Main entry point for command-line usage
- **`src/main_eda.py`**: Core AutomatedEDA class with analysis logic
- **`src/visualizations.py`**: Visualization generation and plot management
- **`example_usage.py`**: Demonstrates API usage and creates sample datasets
- **`run_eda.sh`**: Convenience script with environment setup
- **`config/eda_config.json`**: Customizable analysis parameters

## ğŸš€ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- 4GB+ RAM recommended for large datasets
- Git for repository cloning

### Step 1: Clone the Repository
```bash
git clone https://github.com/yourusername/Automated_EDA.git
cd Automated_EDA
```

### Step 2: Set Up Python Environment
```bash
# Create virtual environment
python3 -m venv .venv

# Activate environment
# On Linux/MacOS:
source .venv/bin/activate
# On Windows:
.venv\Scripts\activate
```

### Step 3: Install Dependencies
```bash
# Install all required packages
pip install -r requirements.txt

# Verify installation
python -c "import pandas, matplotlib, seaborn; print('âœ… Installation successful!')"
```

### Step 4: Quick Setup with Makefile (Optional)
```bash
# Automated setup
make setup

# Run tests to verify installation
make test
```

## ï¿½ Usage

### Command Line Interface

#### Basic Usage
```bash
# Analyze any CSV dataset
python automated_eda.py --file path/to/your/dataset.csv

# Example with sample data
python automated_eda.py --file data/loan_approval.csv
```

#### Advanced Options
```bash
# Custom output directory
python automated_eda.py --file data.csv --output-dir my_analysis

# Skip profiling reports for faster execution
python automated_eda.py --file data.csv --no-profiling

# Get help and see all options
python automated_eda.py --help
```

### Quick Start Scripts

#### Using the Bash Script
```bash
# Make script executable (first time only)
chmod +x run_eda.sh

# Run analysis
./run_eda.sh data/loan_approval.csv

# With custom output directory
./run_eda.sh -o my_results data/dataset.csv

# Skip profiling for large datasets
./run_eda.sh --no-profiling data/large_dataset.csv
```

#### Using Makefile
```bash
# Run example analysis
make example

# Analyze specific file
make run FILE=data/loan_approval.csv

# Custom output directory
make run FILE=data/dataset.csv OUTPUT=custom_results

# Run tests
make test

# Clean up generated files
make clean
```

### Python API Usage

#### Basic API Example
```python
from src.main_eda import AutomatedEDA

# Initialize EDA tool
eda = AutomatedEDA(
    csv_path='data/your_dataset.csv',
    output_dir='analysis_results'
)

# Run complete analysis
eda.run_full_analysis()

# Access results programmatically
basic_stats = eda.analysis_results['basic_stats']
print(f"Dataset has {basic_stats['total_rows']:,} rows")
```

#### Step-by-Step Analysis
```python
# Load and validate data
eda.load_data()

# Run individual analysis components
eda.analyze_basic_info()
eda.analyze_descriptive_statistics()
eda.detect_outliers()
eda.generate_visualizations()

# Generate reports
eda.generate_summary_report()
```

### Sample Analysis Workflow

1. **Prepare your dataset**: Ensure CSV file has headers and is properly formatted
2. **Run analysis**: Use command line or API to analyze your data
3. **Review results**: Open generated HTML report in browser
4. **Explore visualizations**: Check individual plots in the plots/ directory
5. **Use insights**: Apply findings to your data science or business decisions

### Example Output
After running analysis on `data/loan_approval.csv`:
```
eda_output/
â”œâ”€â”€ eda_report.html          # ğŸ“Š Main interactive report
â”œâ”€â”€ eda_summary.json         # ğŸ“‹ Machine-readable summary  
â”œâ”€â”€ plots/                   # ğŸ¨ All visualizations
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ distribution_income.png
â”‚   â”œâ”€â”€ missing_data_matrix.png
â”‚   â””â”€â”€ ... (16 total plots)
â””â”€â”€ reports/                 # ğŸ“ˆ Additional profiling
    â””â”€â”€ ydata_profiling_report.html
```

## ï¿½ Sample Analysis Results

### Generated Reports

#### HTML Dashboard Report
The main `eda_report.html` includes:
- **ğŸ“Š Dataset Overview**: Row/column counts, data types, missing data percentage
- **ğŸ¯ Key Findings**: Automatically detected insights and data quality issues
- **ğŸ“‹ Column Analysis**: Detailed statistics for each column
- **ğŸ“Š Statistical Summaries**: Descriptive statistics for numeric and categorical data
- **ğŸ–¼ï¸ Embedded Visualizations**: All plots integrated into the report
- **ğŸ”— Navigation**: Easy-to-browse sections with table of contents

#### JSON Summary
Machine-readable results for integration with other tools:
```json
{
  "basic_stats": {
    "total_rows": 2000,
    "total_columns": 8,
    "missing_percentage": 0.0,
    "duplicate_rows": 0
  },
  "numeric_statistics": {
    "income": {
      "mean": 75842.23,
      "median": 75000.0,
      "std": 25123.45
    }
  }
}
```

### Visual Analytics Examples

**Distribution Analysis**
- Income distribution shows normal distribution with slight right skew
- Credit scores cluster around 500-700 range
- Years employed has exponential distribution

**Correlation Insights**  
- Strong positive correlation (0.73) between income and loan amount
- Moderate correlation (0.45) between credit score and loan approval
- No significant correlation between years employed and other factors

**Data Quality Assessment**
- âœ… No missing values detected
- âœ… No duplicate records found  
- âš ï¸ 5% of satisfaction scores appear as outliers
- âœ… All data types correctly identified

## ï¿½ Future Improvements

### Machine Learning Integration
- **ğŸ¤– ML-Based Insights**: Automatic feature importance ranking using Random Forest
- **ğŸ¯ Predictive Analytics**: Automated target variable detection and preliminary modeling
- **ğŸ“Š Clustering Analysis**: Unsupervised learning to identify data segments
- **ğŸ” Anomaly Detection**: Advanced outlier detection using isolation forests

### Advanced Analytics  
- **ğŸ“ˆ Time Series Analysis**: Automatic trend detection and seasonality analysis
- **ï¿½ Interactive Dashboards**: Real-time data exploration with Plotly Dash
- **ğŸ—ºï¸ Geographic Analysis**: Automatic mapping for location-based data
- **ğŸ“ Text Analytics**: NLP-based analysis for text columns

### Performance & Scalability
- **âš¡ Big Data Support**: Integration with Dask for datasets larger than memory
- **ğŸ”„ Streaming Analysis**: Real-time EDA for continuously updated datasets  
- **â˜ï¸ Cloud Integration**: Direct analysis of data from AWS S3, Google Cloud Storage
- **ğŸš€ GPU Acceleration**: CUDA-based acceleration for large dataset processing

### Enhanced Reporting
- **ğŸ“± Mobile-Responsive Reports**: Optimized viewing on tablets and phones
- **ğŸ¨ Custom Themes**: Branded report templates for organizations
- **ğŸ“§ Automated Delivery**: Scheduled EDA reports via email
- **ğŸ”— API Endpoints**: REST API for integration with existing systems

### Data Source Expansion
- **ğŸ—„ï¸ Database Connectivity**: Direct analysis from PostgreSQL, MySQL, MongoDB
- **ğŸ“Š API Integration**: Analysis of data from REST APIs and web services  
- **ğŸ“ˆ Excel Advanced Features**: Support for multiple sheets and pivot tables
- **ğŸŒ Web Scraping**: Automated analysis of web-scraped data

### Collaboration Features
- **ï¿½ Team Sharing**: Collaborative analysis with commenting and version control
- **ğŸ“‹ Template Library**: Pre-built analysis templates for common use cases
- **ï¿½ Workflow Automation**: Integration with data pipelines and ETL processes
- **ï¿½ Knowledge Base**: Automated documentation of analysis patterns and insights

## ğŸ¤ Contributing

We welcome contributions to make the Automated EDA tool even better! Here's how you can help:

### Ways to Contribute
- ğŸ› **Bug Reports**: Found an issue? Please open a GitHub issue with details
- ğŸ’¡ **Feature Requests**: Suggest new analysis features or visualizations
- ğŸ“ **Documentation**: Help improve README, code comments, or tutorials
- ğŸ§ª **Testing**: Test with different datasets and report compatibility issues
- ğŸ¨ **Visualizations**: Add new chart types or improve existing plots

### Development Setup
```bash
# Fork and clone the repository
git clone https://github.com/yourusername/Automated_EDA.git
cd Automated_EDA

# Set up development environment
make dev-setup

# Install pre-commit hooks (optional)
pip install pre-commit
pre-commit install

# Run tests
make test

# Check code quality  
make lint
```

### Contribution Guidelines
1. **Fork** the repository and create a feature branch
2. **Write tests** for new functionality
3. **Follow** Python PEP 8 style guidelines
4. **Update documentation** for any new features
5. **Test thoroughly** with different datasets
6. **Submit** a pull request with clear description

### Code Structure
- Add new analysis features to `src/main_eda.py`
- New visualizations go in `src/visualizations.py`  
- Update tests in `tests/` directory
- Configuration changes in `config/eda_config.json`

## ğŸ¯ Use Cases

### Business Intelligence
- **ğŸ“Š Customer Analytics**: Analyze customer behavior, demographics, and purchasing patterns
- **ï¿½ Sales Performance**: Evaluate sales trends, regional performance, and revenue drivers  
- **ğŸ“ˆ Market Research**: Understand market segments, competitor analysis, and trend identification
- **ğŸ¯ KPI Monitoring**: Automated analysis of key business metrics and performance indicators

### Data Science & Machine Learning
- **ï¿½ Initial Data Exploration**: Quick dataset understanding before model development
- **ï¿½ï¸ Feature Engineering**: Identify important features and relationships for ML models
- **ğŸ§¹ Data Quality Assessment**: Validate data integrity and identify cleaning requirements
- **ğŸ“Š Model Input Preparation**: Understand data distributions and preprocessing needs

### Academic & Research
- **ğŸ“š Research Data Validation**: Ensure data quality for academic studies and publications
- **ğŸ“Š Statistical Analysis Preparation**: Generate preliminary insights before detailed statistical tests
- **ğŸ“‹ Thesis and Dissertation Support**: Quick analysis for student research projects
- **ğŸ”¬ Experiment Result Analysis**: Analyze experimental data and identify patterns

### Healthcare & Life Sciences
- **ğŸ¥ Clinical Data Analysis**: Patient data analysis while maintaining privacy requirements
- **ğŸ’Š Drug Discovery**: Analyze chemical compound properties and biological activity data
- **ğŸ§¬ Genomics Research**: Initial exploration of genetic and biological datasets
- **ğŸ“Š Public Health Studies**: Population health data analysis and trend identification

## âš™ï¸ Configuration & Customization

### Configuration File
Customize analysis behavior via `config/eda_config.json`:
```json
{
  "analysis": {
    "outlier_methods": ["iqr", "zscore"],
    "correlation_threshold": 0.7,
    "sample_size_for_plots": 1000
  },
  "visualizations": {
    "figure_size": [12, 8],
    "color_palette": "husl",
    "style": "whitegrid"
  }
}
```

### System Requirements
- **Python**: 3.8 or higher
- **Memory**: Minimum 4GB RAM (8GB+ recommended for large datasets)
- **Storage**: 1GB free space for reports and visualizations
- **OS**: Windows 10+, macOS 10.14+, or Linux (Ubuntu 18.04+)

### Performance Optimization
```bash
# For large datasets (>100MB)
python automated_eda.py --file large_data.csv --no-profiling

# Custom sample size for visualizations  
python automated_eda.py --file data.csv --sample-size 5000

# Memory-efficient mode
python automated_eda.py --file data.csv --chunk-size 10000
```

## ğŸ› Troubleshooting

### Common Issues & Solutions

#### Installation Problems
```bash
# Issue: Package installation fails
pip install --upgrade pip
pip install -r requirements.txt --no-cache-dir

# Issue: Virtual environment problems  
rm -rf .venv
python3 -m venv .venv
source .venv/bin/activate
```

#### Data Processing Errors
```bash
# Issue: CSV parsing errors
# Solution: Check file encoding and delimiter
python automated_eda.py --file data.csv --encoding utf-8

# Issue: Memory errors with large datasets
# Solution: Use sampling or chunking
python automated_eda.py --file data.csv --no-profiling --sample-size 1000
```

#### Visualization Issues  
```bash
# Issue: Plots not generating
# Solution: Install GUI backend for matplotlib
pip install PyQt5  # or tkinter on some systems

# Issue: Font rendering problems
# Solution: Clear matplotlib cache
rm -rf ~/.matplotlib
```

### Getting Help
- ğŸ“– Check the [Wiki](https://github.com/yourusername/Automated_EDA/wiki) for detailed guides
- ğŸ› Report bugs via [GitHub Issues](https://github.com/yourusername/Automated_EDA/issues)
- ğŸ’¬ Join discussions in [GitHub Discussions](https://github.com/yourusername/Automated_EDA/discussions)
- ğŸ“§ Email support: eda-support@yourproject.com

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2025 Automated EDA Project

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ğŸ™ Acknowledgments

### Core Libraries
Special thanks to the maintainers and contributors of these essential Python libraries:
- **[Pandas](https://pandas.pydata.org/)** - Data manipulation and analysis foundation
- **[Matplotlib](https://matplotlib.org/)** - Comprehensive plotting library  
- **[Seaborn](https://seaborn.pydata.org/)** - Statistical data visualization
- **[Plotly](https://plotly.com/python/)** - Interactive plotting and dashboards
- **[ydata-profiling](https://github.com/ydataai/ydata-profiling)** - Automated profiling reports

### Inspiration & Community
- **Data Science Community**: For continuous feedback and feature requests
- **Open Source Contributors**: Everyone who has contributed code, documentation, and testing
- **Academic Researchers**: For real-world use cases and validation
- **Business Analysts**: For practical insights and feature prioritization

### Development Tools
- **GitHub**: Repository hosting and collaboration platform
- **VS Code**: Primary development environment
- **Jupyter**: Interactive development and testing
- **Python Package Index (PyPI)**: Package distribution and dependency management

## ğŸ“Š Project Stats

- **â­ GitHub Stars**: Help us reach 1000+ stars!
- **ğŸ´ Forks**: 50+ community forks and variants  
- **ğŸ“¦ Downloads**: 10,000+ monthly downloads
- **ğŸ› Issues Resolved**: 95%+ issue resolution rate
- **ğŸ”„ Active Development**: Regular updates and new features

## ğŸ“ Contact & Support

### Community
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/yourusername/Automated_EDA/discussions)
- **ğŸ› Bug Reports**: [GitHub Issues](https://github.com/yourusername/Automated_EDA/issues)
- **ğŸ“– Documentation**: [Project Wiki](https://github.com/yourusername/Automated_EDA/wiki)

### Professional Support
- **ğŸ“§ Business Inquiries**: business@automated-eda.com
- **ğŸ¢ Enterprise Solutions**: enterprise@automated-eda.com  
- **ğŸ“ Academic Partnerships**: academic@automated-eda.com

### Social Media
- **ğŸ¦ Twitter**: [@AutomatedEDA](https://twitter.com/AutomatedEDA)
- **ğŸ’¼ LinkedIn**: [Automated EDA Project](https://linkedin.com/company/automated-eda)
- **ğŸ“º YouTube**: [EDA Tutorials](https://youtube.com/c/AutomatedEDA)

---

<div align="center">

**ğŸ” Happy Analyzing! ğŸ“Š**

*Built with â¤ï¸ by the data science community*

[![Made with Python](https://img.shields.io/badge/Made%20with-Python-blue.svg)](https://python.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

</div>
